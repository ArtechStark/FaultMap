{
 "metadata": {
  "name": "transfer_entopy_example_custom"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import stats\n",
      "import numpy as np\n",
      "from numpy import vstack"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 444
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def autogen(samples, delay):\n",
      "    \"\"\"Generate an autoregressive set of vectors.\"\"\"\n",
      "\n",
      "    source = np.random.randn(samples + delay + 1)\n",
      "    pred = np.zeros_like(source)\n",
      "\n",
      "    for i in range(delay, len(source)):\n",
      "        pred[i] = pred[i - 1] + source[i - delay]\n",
      "\n",
      "    pred = pred[delay:-1]\n",
      "    source = source[delay:-1]\n",
      "\n",
      "    data = vstack([pred, source])\n",
      "\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 445
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorselection(data, timelag, sub_samples, k, l):\n",
      "    \"\"\"Generates sets of vectors for calculating transfer entropy.\n",
      "\n",
      "    For notation references see Shu2013.\n",
      "\n",
      "    Takes into account the time lag (number of samples between vectors of the\n",
      "    same variable).\n",
      "\n",
      "    In this application the prediction horizon (h) is set to equal\n",
      "    to the time lag.\n",
      "\n",
      "    The first vector in the data array should be the samples of the variable\n",
      "    to be predicted (x) while the second vector should be sampled of the vector\n",
      "    used to make the prediction (y).\n",
      "\n",
      "    sub_samples is the amount of samples in the dataset used to calculate the\n",
      "    transfer entropy between two vectors.\n",
      "    The required number of samples is extracted from the end of the vector.\n",
      "    If the vector is longer than the number of samples specified plus the\n",
      "    desired time lag then the remained of the data will be discarded.\n",
      "    sub_samples <= samples\n",
      "\n",
      "\n",
      "    k refers to the dimension of the historical data to be predicted (x)\n",
      "\n",
      "    l refers to the dimension of the historical data used\n",
      "    to do the prediction (y)\n",
      "\n",
      "    \"\"\"\n",
      "    _, sample_n = data.shape\n",
      "    x_pred = data[0, sample_n-sub_samples-1:-1]\n",
      "\n",
      "    x_hist = np.zeros((k, sub_samples))\n",
      "    y_hist = np.zeros((l, sub_samples))\n",
      "\n",
      "    for n in range(1, (k+1)):\n",
      "        # Original form according to Bauer (2007)\n",
      "#        x_hist[n-1, :] = data[0, ((sample_n - samples) - timelag * n):\n",
      "#                               (sample_n - timelag * n)]\n",
      "        # Modified form according to Shu & Zhao (2013)\n",
      "        x_hist[n-1, :] = data[0, ((sample_n - sub_samples) - timelag *\n",
      "                                  (n-1) - 1):(sample_n - timelag * (n-1) - 1)]\n",
      "    for m in range(1, (l+1)):\n",
      "        y_hist[m-1:, :] = data[1, ((sample_n - sub_samples) - timelag * m):\n",
      "                               (sample_n - timelag * m)]\n",
      "\n",
      "#    for n in range(1, (k+1)):\n",
      "#        x_hist = data[0, ((sample_n - samples) - timelag * n):\n",
      "#                            (sample_n - timelag * n)]\n",
      "#    for m in range(1, (l+1)):\n",
      "#        y_hist = data[1, ((sample_n - samples) - timelag * m):\n",
      "#                            (sample_n - timelag * m)]\n",
      "\n",
      "    return x_pred, x_hist, y_hist\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 446
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pdfcalcs(x_pred, x_hist, y_hist):\n",
      "    \"\"\"Calculates the PDFs required to calculate transfer entropy.\n",
      "\n",
      "    Currently only supports k = 1; l = 1\n",
      "\n",
      "    \"\"\"\n",
      "    # TODO: Generalize for k and l\n",
      "\n",
      "    # Get dimensions of vectors\n",
      "#    k = np.size(x_hist[:, 1])\n",
      "#    l = np.size(y_hist[:, 1])\n",
      "\n",
      "    # Calculate p(x_{i+h}, x_i, y_i)\n",
      "    data_1 = np.vstack([x_pred, x_hist[0, :], y_hist[0, :]])\n",
      "    pdf_1 = stats.gaussian_kde(data_1, 'silverman')\n",
      "\n",
      "    # Calculate p(x_i, y_i)\n",
      "    data_2 = np.vstack([x_hist[0, :], y_hist[0, :]])\n",
      "    pdf_2 = stats.gaussian_kde(data_2, 'silverman')\n",
      "\n",
      "    # Calculate p(x_{i+h}, x_i)\n",
      "    data_3 = np.vstack([x_pred, x_hist[0, :]])\n",
      "    pdf_3 = stats.gaussian_kde(data_3, 'silverman')\n",
      "\n",
      "    # Calculate p(x_i)\n",
      "    data_4 = x_hist[0, :]\n",
      "    pdf_4 = stats.gaussian_kde(data_4, 'silverman')\n",
      "\n",
      "    return pdf_1, pdf_2, pdf_3, pdf_4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 447
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pdfcalcs_custom(x_pred, x_hist, y_hist, x_pred_val, x_hist_val, y_hist_val):\n",
      "    \"\"\"Evaluates the PDFs required to calculate transfer entropy.\n",
      "\n",
      "    Currently only supports k = 1; l = 1\n",
      "\n",
      "    \"\"\"\n",
      "    # TODO: Generalize for k and l\n",
      "\n",
      "    # Get dimensions of vectors\n",
      "#    k = np.size(x_hist[:, 1])\n",
      "#    l = np.size(y_hist[:, 1])\n",
      "\n",
      "    # Calculate p(x_{i+h}, x_i, y_i)\n",
      "    data_1 = np.vstack([x_pred, x_hist[0, :], y_hist[0, :]])\n",
      "    pdf_1 = joint_pdf_eval(data_1, [x_pred_val, x_hist_val, y_hist_val]) \n",
      "    #pdf_1 = stats.gaussian_kde(data_1, 'silverman')\n",
      "\n",
      "    # Calculate p(x_i, y_i)\n",
      "    data_2 = np.vstack([x_hist[0, :], y_hist[0, :]])\n",
      "    pdf_2 = joint_pdf_eval(data_2, [x_hist_val, y_hist_val])\n",
      "    #pdf_2 = stats.gaussian_kde(data_2, 'silverman')\n",
      "\n",
      "    # Calculate p(x_{i+h}, x_i)\n",
      "    data_3 = np.vstack([x_pred, x_hist[0, :]])\n",
      "    pdf_3 = joint_pdf_eval(data_3, [x_pred_val, x_hist_val])\n",
      "    #pdf_3 = stats.gaussian_kde(data_3, 'silverman')\n",
      "\n",
      "    # Calculate p(x_i)\n",
      "    data_4 = np.vstack(x_hist[0, :])\n",
      "    pdf_4 = joint_pdf_eval(data_4, [x_hist_val])\n",
      "    #pdf_4 = stats.gaussian_kde(data_4, 'silverman')\n",
      "\n",
      "    return pdf_1, pdf_2, pdf_3, pdf_4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 448
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def te_elementcalc(pdf_1, pdf_2, pdf_3, pdf_4, x_pred_val,\n",
      "                   x_hist_val, y_hist_val):\n",
      "    \"\"\"Calculate elements for summation for a specific set of coordinates\"\"\"\n",
      "\n",
      "    # Need to find a proper way to correct for cases when PDFs return 0\n",
      "    # Most of the PDF issues are associated with the x_hist values being\n",
      "    # very similar to the x_pred values\n",
      "    # Some very small negative values are sometimes returned\n",
      "\n",
      "    # Function evaluations\n",
      "    term1 = pdf_1([x_pred_val, x_hist_val, y_hist_val])\n",
      "    term2 = pdf_2([x_hist_val, y_hist_val])\n",
      "    term3 = pdf_3([x_pred_val, x_hist_val])\n",
      "    term4 = pdf_4([x_hist_val])\n",
      "#    print term1, term2, term3, term4\n",
      "\n",
      "    # Assign zero value if nan is returned\n",
      "\n",
      "#    print term1, term2, term3, term4\n",
      "    if term1 < 0 or term2 < 0 or term3 < 0 or term4 < 0:\n",
      "        print term1, term2, term3, term4\n",
      "\n",
      "#    else:\n",
      "#        logterm_num = (term1 / term2)\n",
      "#        logterm_den = (term3 / term4)\n",
      "#        coeff = term1\n",
      "#        sum_element = coeff * np.log(logterm_num / logterm_den)\n",
      "#        print np.log(logterm_num / logterm_den)\n",
      "\n",
      "    logterm_num = (term1 / term2)\n",
      "    logterm_den = (term3 / term4)\n",
      "    coeff = term1\n",
      "    sum_element = coeff * np.log(logterm_num / logterm_den)\n",
      "\n",
      "    if sum_element == np.nan:\n",
      "        sum_element = 0\n",
      "\n",
      "    return sum_element"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 449
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def te_elementcalc_custom(x_pred, x_hist, y_hist, x_pred_val,\n",
      "                   x_hist_val, y_hist_val):\n",
      "    \"\"\"Calculate elements for summation for a specific set of coordinates\"\"\"\n",
      "\n",
      "    # Need to find a proper way to correct for cases when PDFs return 0\n",
      "    # Most of the PDF issues are associated with the x_hist values being\n",
      "    # very similar to the x_pred values\n",
      "    # Some very small negative values are sometimes returned\n",
      "\n",
      "    # Function evaluations\n",
      "    \n",
      "    [term1, term2, term3, term4] = pdfcalcs_custom(x_pred, x_hist, y_hist, x_pred_val, x_hist_val, y_hist_val)\n",
      "#    print term1, term2, term3, term4\n",
      "\n",
      "    # Assign zero value if nan is returned\n",
      "\n",
      "#    print term1, term2, term3, term4\n",
      "    if term1 < 0 or term2 < 0 or term3 < 0 or term4 < 0:\n",
      "        print term1, term2, term3, term4\n",
      "#\n",
      "#    else:\n",
      "#        logterm_num = (term1 / term2)\n",
      "#        logterm_den = (term3 / term4)\n",
      "#        coeff = term1\n",
      "#        sum_element = coeff * np.log(logterm_num / logterm_den)\n",
      "#        print np.log(logterm_num / logterm_den)\n",
      "\n",
      "    logterm_num = (term1 / term2)\n",
      "    logterm_den = (term3 / term4)\n",
      "    coeff = term1\n",
      "    sum_element = coeff * np.log(logterm_num / logterm_den)\n",
      "\n",
      "    if (sum_element == np.nan or sum_element < 0):\n",
      "        sum_element = 0\n",
      "\n",
      "    return sum_element"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 450
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def te_calc(x_pred, x_hist, y_hist, ampbins):\n",
      "    \"\"\"Calculates the transfer entropy between two variables from a set of\n",
      "    vectors already calculated.\n",
      "\n",
      "    ampbins is the number of amplitude bins to use over each variable\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    # First do an example for the case of k = l = 1\n",
      "    # TODO: Sum loops to allow for a general case\n",
      "\n",
      "    # Divide the range of each variable into amplitude bins to sum over\n",
      "\n",
      "    x_pred_min = x_pred.min()\n",
      "    x_pred_max = x_pred.max()\n",
      "    x_hist_min = x_hist.min()\n",
      "    x_hist_max = x_hist.max()\n",
      "    y_hist_min = y_hist.min()\n",
      "    y_hist_max = y_hist.max()\n",
      "\n",
      "    x_pred_space = np.linspace(x_pred_min, x_pred_max, ampbins)\n",
      "    x_hist_space = np.linspace(x_hist_min, x_hist_max, ampbins)\n",
      "    y_hist_space = np.linspace(y_hist_min, y_hist_max, ampbins)\n",
      "\n",
      "    x_pred_diff = x_pred_space[1] - x_pred_space[0]\n",
      "    x_hist_diff = x_hist_space[1] - x_hist_space[0]\n",
      "    y_hist_diff = y_hist_space[1] - y_hist_space[0]\n",
      "\n",
      "    # Calculate PDFs for all combinations required\n",
      "    [pdf_1, pdf_2, pdf_3, pdf_4] = pdfcalcs(x_pred, x_hist, y_hist)\n",
      "\n",
      "    # Consecutive sums\n",
      "    # TODO: Make sure Riemann sum diff elements is handled correctly\n",
      "\n",
      "    tesum = 0\n",
      "#    tesum_old = -1\n",
      "#    sumelement_store = np.zeros(ampbins**3)\n",
      "    delement = x_pred_diff * x_hist_diff * y_hist_diff\n",
      "    print 'delement',  delement\n",
      "    for s1 in x_pred_space:\n",
      "#        print 's1', s1\n",
      "        for s2 in x_hist_space:\n",
      "#            print 's2', s2\n",
      "            for s3 in y_hist_space:\n",
      "#                print 's3', s3\n",
      "                sum_element = te_elementcalc(pdf_1, pdf_2, pdf_3, pdf_4,\n",
      "                                             s1, s2, s3)\n",
      "                tesum = tesum + sum_element\n",
      "                # Try to detect point at which the huge term enters\n",
      "                # For special case of data = np.vstack([puretf, original])\n",
      "                # and timelag = 1 and ampbins = 20\n",
      "                # Has to do with a huge value for PDF1 at a specific point\n",
      "#                if tesum / tesum_old < 0:\n",
      "#                    print s1, s2, s3\n",
      "#                    temp1 = pdf_1([s1, s2, s3])\n",
      "#                    temp2 = pdf_2([s2, s3])\n",
      "#                    temp3 = pdf_3([s1, s2])\n",
      "#                    temp4 = pdf_4([s2])\n",
      "#                    print temp1, temp2, temp3, temp4\n",
      "#                tesum_old = tesum\n",
      "#                print tesum\n",
      "#                sumelement_store[s1*s2*s3] = sum_element\n",
      "    tentropy = tesum * delement\n",
      "\n",
      "    # Using local sums\n",
      "    # (It does give the same result)\n",
      "\n",
      "#    sums3 = 0\n",
      "#    sums2 = 0\n",
      "#    sums1 = 0\n",
      "#    for s1 in x_pred_space:\n",
      "#        print s1\n",
      "#        sums2 = 0\n",
      "#        for s2 in x_hist_space:\n",
      "##            print s2\n",
      "#            sums3 = 0\n",
      "#            for s3 in y_hist_space:\n",
      "#                sum_element = tecalc(pdf_1, pdf_2, pdf_3, pdf_4, s1, s2, s3)\n",
      "#                sums3 = sums3 + sum_element\n",
      "#            sums2 = sums2 + sums3 * y_hist_diff\n",
      "#        sums1 = sums1 + sums2 * x_hist_diff\n",
      "#        te = sums1 * x_pred_diff\n",
      "\n",
      "    return tentropy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 451
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def te_calc_custom(x_pred, x_hist, y_hist, ampbins):\n",
      "    \"\"\"Calculates the transfer entropy between two variables from a set of\n",
      "    vectors already calculated.\n",
      "\n",
      "    ampbins is the number of amplitude bins to use over each variable\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    # First do an example for the case of k = l = 1\n",
      "    # TODO: Sum loops to allow for a general case\n",
      "\n",
      "    # Divide the range of each variable into amplitude bins to sum over\n",
      "    \n",
      "    # Set the number of amplitude bins equal to the number of samples for now to avoid having to rewrite a large number of code\n",
      "    # FIXME: There is discretization taking place here, although discretization is not taken into account explicitly\n",
      "    #       in the evaluation of the joint PDFs.\n",
      "    # FIXME: There might be some confusion regarding the difference between amplitude bins used in calculating transfer entropy\n",
      "    #        and in evaluating the PDF itself.\n",
      "\n",
      "    x_pred_min = x_pred.min()\n",
      "    x_pred_max = x_pred.max()\n",
      "    x_hist_min = x_hist.min()\n",
      "    x_hist_max = x_hist.max()\n",
      "    y_hist_min = y_hist.min()\n",
      "    y_hist_max = y_hist.max()\n",
      "\n",
      "    x_pred_space = np.linspace(x_pred_min, x_pred_max, ampbins)\n",
      "    x_hist_space = np.linspace(x_hist_min, x_hist_max, ampbins)\n",
      "    y_hist_space = np.linspace(y_hist_min, y_hist_max, ampbins)\n",
      "\n",
      "    x_pred_diff = x_pred_space[1] - x_pred_space[0]\n",
      "    x_hist_diff = x_hist_space[1] - x_hist_space[0]\n",
      "    y_hist_diff = y_hist_space[1] - y_hist_space[0]\n",
      "\n",
      "    # Calculate PDFs for all combinations required\n",
      "    # UPDATE: Not needed in custom method as PDFs are evaluated at each point\n",
      "    #[pdf_1, pdf_2, pdf_3, pdf_4] = pdfcalcs(x_pred, x_hist, y_hist)\n",
      "\n",
      "    # Consecutive sums\n",
      "    # TODO: Make sure Riemann sum diff elements is handled correctly\n",
      "\n",
      "    tesum = 0\n",
      "#    tesum_old = -1\n",
      "#    sumelement_store = np.zeros(ampbins**3)\n",
      "    delement = x_pred_diff * x_hist_diff * y_hist_diff\n",
      "    print 'delement', delement\n",
      "    for s1 in x_pred_space:\n",
      "        print 's1', s1\n",
      "        for s2 in x_hist_space:\n",
      "            print 's2', s2\n",
      "            for s3 in y_hist_space:\n",
      "#                print 's3', s3\n",
      "                sum_element = te_elementcalc_custom(x_pred, x_hist, y_hist, s1, s2, s3)\n",
      "                tesum = tesum + sum_element\n",
      "                # Try to detect point at which the huge term enters\n",
      "                # For special case of data = np.vstack([puretf, original])\n",
      "                # and timelag = 1 and ampbins = 20\n",
      "                # Has to do with a huge value for PDF1 at a specific point\n",
      "#                if tesum / tesum_old < 0:\n",
      "#                    print s1, s2, s3\n",
      "#                    temp1 = pdf_1([s1, s2, s3])\n",
      "#                    temp2 = pdf_2([s2, s3])\n",
      "#                    temp3 = pdf_3([s1, s2])\n",
      "#                    temp4 = pdf_4([s2])\n",
      "#                    print temp1, temp2, temp3, temp4\n",
      "#                tesum_old = tesum\n",
      "#                print tesum\n",
      "#                sumelement_store[s1*s2*s3] = sum_element\n",
      "    tentropy = tesum * delement\n",
      "\n",
      "    # Using local sums\n",
      "    # (It does give the same result)\n",
      "\n",
      "#    sums3 = 0\n",
      "#    sums2 = 0\n",
      "#    sums1 = 0\n",
      "#    for s1 in x_pred_space:\n",
      "#        print s1\n",
      "#        sums2 = 0\n",
      "#        for s2 in x_hist_space:\n",
      "##            print s2\n",
      "#            sums3 = 0\n",
      "#            for s3 in y_hist_space:\n",
      "#                sum_element = tecalc(pdf_1, pdf_2, pdf_3, pdf_4, s1, s2, s3)\n",
      "#                sums3 = sums3 + sum_element\n",
      "#            sums2 = sums2 + sums3 * y_hist_diff\n",
      "#        sums1 = sums1 + sums2 * x_hist_diff\n",
      "#        te = sums1 * x_pred_diff\n",
      "\n",
      "    return tentropy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 452
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getdata(samples, delay):\n",
      "    \"\"\"Get dataset for testing.\n",
      "\n",
      "    Select to generate each run or import an existing dataset.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    # Generate autoregressive delayed data vectors internally\n",
      "    data = autogen(samples, delay)\n",
      "\n",
      "    # Alternatively, import data from file\n",
      "#    autoregx = loadtxt('autoregx_data.csv')\n",
      "#    autoregy = loadtxt('autoregy_data.csv')\n",
      "\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 453
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calculate_te(delay, timelag, samples, sub_samples, ampbins, k=1, l=1):\n",
      "    \"\"\"Calculates the transfer entropy for a specific timelag (equal to\n",
      "    prediction horison) for a set of autoregressive data.\n",
      "\n",
      "    sub_samples is the amount of samples in the dataset used to calculate the\n",
      "    transfer entropy between two vectors (taken from the end of the dataset).\n",
      "    sub_samples <= samples\n",
      "\n",
      "    Currently only supports k = 1; l = 1;\n",
      "\n",
      "    You can search through a set of timelags in an attempt to identify the\n",
      "    original delay.\n",
      "    The transfer entropy should have a maximum value when timelag = delay\n",
      "    used to generate the autoregressive dataset.\n",
      "\n",
      "    \"\"\"\n",
      "    # Get autoregressive datasets\n",
      "    data = getdata(samples, delay)\n",
      "\n",
      "    [x_pred, x_hist, y_hist] = vectorselection(data, timelag,\n",
      "                                               sub_samples, k, l)\n",
      "\n",
      "    #transentropy = te_calc(x_pred, x_hist, y_hist, ampbins)\n",
      "    transentropy = te_calc_custom(x_pred, x_hist, y_hist, ampbins)\n",
      "\n",
      "    return transentropy\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 454
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The bandwidth selection tries to compute the inverse of the partial correlation matrix, which fails for this dataset.\n",
      "# Will attempt to implement the manual bandwidth selection code instead.\n",
      "# Manual PDF functions will be written"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 455
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def theta_calc(data, variables):\n",
      "    C = (4.0/3.0)**(1.0/5.0)\n",
      "    sigma = np.std(data)\n",
      "    N = len(data)\n",
      "    theta = C * sigma * (N**(-1.0/(4.0 + variables)))\n",
      "    return theta\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 456
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def kernel_calc(data, sample, value, variables):\n",
      "    \"\"\"Calculates a single single-variable Gaussian Kernel.\n",
      "\n",
      "    data is the single variable set of sample points\n",
      "    sample is the element of the data set used in the calculation of the single kernel\n",
      "    value is the point according to which the probability density function is evaluated\n",
      "    variables is the number of variables involved in the greater multivariable PDF calculation of which this kernel will form a part\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    theta = theta_calc(data, variables)\n",
      "    kernel = (1.0 / (np.sqrt(2*np.pi) * theta)) * np.exp(-(value - sample)**2 / (2 * (theta**2)))\n",
      "    return kernel     "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 457
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def joint_pdf_eval(data, values):\n",
      "    \"\"\"Evaluates the joint (multivariable) probability density function for a specific set of values.\n",
      "\n",
      "    data is the multidimensional array containing all samples for all variables\n",
      "    values is the set of values around which the joint PDF is to be evaluated\n",
      "\n",
      "    \"\"\"\n",
      "    \n",
      "    if (np.shape(data)[0] > np.shape(data)[1]):\n",
      "        # This catches the case of a single variable\n",
      "        (numsamples, numvars) = np.shape(data)\n",
      "    else:\n",
      "        (numvars, numsamples) = np.shape(data)\n",
      "\n",
      "    \n",
      "    # TODO: Test that samples and number of variable in data has the same dimension.\n",
      "    # TODO: Implement amplitude bins in order to select points to use as samples\n",
      "    #       First write for the case where all variables use the same number of ampbins\n",
      "    #       Follow the implementation of Bauer for calculating amplitude bins\n",
      "    kernel_sum = 0\n",
      "    #samples = np.zeros([numvars, ampbins])\n",
      "    #mins = np.zeros([1, numvars])\n",
      "    #maxs = np.zeros([1, numvars])\n",
      "    for i in range(numsamples):\n",
      "        kernel_prod = 1\n",
      "        if numvars == 1:\n",
      "            kernel_prod = kernel_prod * kernel_calc(data, data[i], values, numvars)\n",
      "        elif (numvars > 1):\n",
      "            for n in range(numvars):\n",
      "                #mins[n] = data[n].min()\n",
      "                #maxs[n] = data[n].max()\n",
      "                #samples[n] = np.linsapce(mins[n], maxs[n], ampbins)\n",
      "                kernel_prod = kernel_prod * kernel_calc(data[n], data[n][i], values[n], numvars)\n",
      "                \n",
      "        kernel_sum += kernel_prod\n",
      "    \n",
      "    prob = (1.0 / numsamples) * kernel_sum\n",
      "    return prob       \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 458
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate data for tests\n",
      "DATA = getdata(1000, 5)\n",
      "[X_PRED, X_HIST, Y_HIST] = vectorselection(DATA, 4, 400, 1, 1)\n",
      "DATA_1 = np.vstack([X_PRED, X_HIST[0, :], Y_HIST[0, :]])\n",
      "DATA_4 = np.vstack(X_HIST[0, :])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 459
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PDF_1 = stats.gaussian_kde(DATA_1, 'silverman')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 460
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculate transfer entropy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 461
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "calculate_te(5, 5, 110, 100, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "delement 1.48106870382\n",
        "s1 -4.21935709881\n",
        "s2 -4.21935709881\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -2.52599446877\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.83263183873\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.860730791309\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.55409342135\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.24745605139\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.94081868143\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.63418131146\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9.3275439415\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11.0209065715\n",
        "s1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -2.52599446877\n",
        "s2 -4.21935709881\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -2.52599446877\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.83263183873\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.860730791309\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.55409342135\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.24745605139\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.94081868143\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.63418131146\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9.3275439415\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11.0209065715\n",
        "s1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.83263183873\n",
        "s2 -4.21935709881\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -2.52599446877\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.83263183873\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.860730791309\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.55409342135\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.24745605139\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.94081868143\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.63418131146\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9.3275439415\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11.0209065715\n",
        "s1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.860730791309\n",
        "s2 -4.21935709881\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -2.52599446877\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.83263183873\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.860730791309\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.55409342135\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.24745605139\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.94081868143\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.63418131146\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9.3275439415\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11.0209065715\n",
        "s1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.55409342135\n",
        "s2 -4.21935709881\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -2.52599446877\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.83263183873\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.860730791309\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.55409342135\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.24745605139\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.94081868143\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.63418131146\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9.3275439415\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11.0209065715\n",
        "s1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.24745605139\n",
        "s2 -4.21935709881\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -2.52599446877\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.83263183873\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.860730791309\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.55409342135\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.24745605139\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.94081868143\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.63418131146\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9.3275439415\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11.0209065715\n",
        "s1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.94081868143\n",
        "s2 -4.21935709881\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -2.52599446877\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.83263183873\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.860730791309\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.55409342135\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.24745605139\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.94081868143\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.63418131146\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9.3275439415\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11.0209065715\n",
        "s1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.63418131146\n",
        "s2 -4.21935709881\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -2.52599446877\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.83263183873\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.860730791309\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.55409342135\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.24745605139\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.94081868143\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.63418131146\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9.3275439415\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11.0209065715\n",
        "s1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9.3275439415\n",
        "s2 -4.21935709881\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -2.52599446877\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.83263183873\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.860730791309\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.55409342135\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.24745605139\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.94081868143\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.63418131146\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9.3275439415\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11.0209065715\n",
        "s1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11.0209065715\n",
        "s2 -4.21935709881\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -2.52599446877\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -0.83263183873\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.860730791309\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.55409342135\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.24745605139\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.94081868143\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.63418131146\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9.3275439415\n",
        "s2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11.0209065715\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 462,
       "text": [
        "array([ 0.05920812])"
       ]
      }
     ],
     "prompt_number": 462
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Find out where the negative terms come from"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 463
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test different combinations of vectors in normal way"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 464
    }
   ],
   "metadata": {}
  }
 ]
}