{
 "metadata": {
  "name": "transfer_entopy_example_custom_discrete"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import stats\n",
      "import numpy as np\n",
      "from numpy import vstack"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 491
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def autogen(samples, delay):\n",
      "    \"\"\"Generates an autoregressive set of vectors.\"\"\"\n",
      "\n",
      "    source = np.random.randn(samples + delay + 1)\n",
      "    pred = np.zeros_like(source)\n",
      "\n",
      "    for i in range(delay, len(source)):\n",
      "        pred[i] = pred[i - 1] + source[i - delay]\n",
      "\n",
      "    pred = pred[delay:-1]\n",
      "    source = source[delay:-1]\n",
      "\n",
      "    data = vstack([pred, source])\n",
      "\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 492
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getdata(samples, delay):\n",
      "    \"\"\"Get dataset for testing.\n",
      "\n",
      "    Select to generate each run or import an existing dataset.\n",
      "\n",
      "    \"\"\"\n",
      "    # Generate autoregressive delayed data vectors internally\n",
      "    data = autogen(samples, delay)\n",
      "\n",
      "    # Alternatively, import data from file\n",
      "#    autoregx = loadtxt('autoregx_data.csv')\n",
      "#    autoregy = loadtxt('autoregy_data.csv')\n",
      "\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 493
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorselection(data, timelag, sub_samples, k=1, l=1):\n",
      "    \"\"\"Generates sets of vectors for calculating transfer entropy.\n",
      "\n",
      "    For notation references see Shu2013.\n",
      "\n",
      "    Takes into account the time lag (number of samples between vectors of the\n",
      "    same variable).\n",
      "\n",
      "    In this application the prediction horizon (h) is set to equal\n",
      "    to the time lag.\n",
      "\n",
      "    The first vector in the data array should be the samples of the variable\n",
      "    to be predicted (x) while the second vector should be sampled of the vector\n",
      "    used to make the prediction (y).\n",
      "\n",
      "    sub_samples is the amount of samples in the dataset used to calculate the\n",
      "    transfer entropy between two vectors.\n",
      "    The required number of samples is extracted from the end of the vector.\n",
      "    If the vector is longer than the number of samples specified plus the\n",
      "    desired time lag then the remained of the data will be discarded.\n",
      "    sub_samples <= samples\n",
      "\n",
      "\n",
      "    k refers to the dimension of the historical data to be predicted (x)\n",
      "\n",
      "    l refers to the dimension of the historical data used\n",
      "    to do the prediction (y)\n",
      "\n",
      "    \"\"\"\n",
      "    _, sample_n = data.shape\n",
      "    x_pred = data[0, sample_n-sub_samples-1:-1]\n",
      "\n",
      "    x_hist = np.zeros((k, sub_samples))\n",
      "    y_hist = np.zeros((l, sub_samples))\n",
      "\n",
      "    for n in range(1, (k+1)):\n",
      "        # Original form according to Bauer (2007)\n",
      "#        x_hist[n-1, :] = data[0, ((sample_n - samples) - timelag * n):\n",
      "#                               (sample_n - timelag * n)]\n",
      "        # Modified form according to Shu & Zhao (2013)\n",
      "        x_hist[n-1, :] = data[0, ((sample_n - sub_samples) - timelag *\n",
      "                                  (n-1) - 2):(sample_n - timelag * (n-1) - 2)]\n",
      "    for m in range(1, (l+1)):\n",
      "        y_hist[m-1:, :] = data[1, ((sample_n - sub_samples) - timelag * (m) - 1):\n",
      "                               (sample_n - timelag * (m) - 1)]\n",
      "\n",
      "#    for n in range(1, (k+1)):\n",
      "#        x_hist = data[0, ((sample_n - samples) - timelag * n):\n",
      "#                            (sample_n - timelag * n)]\n",
      "#    for m in range(1, (l+1)):\n",
      "#        y_hist = data[1, ((sample_n - samples) - timelag * m):\n",
      "#                            (sample_n - timelag * m)]\n",
      "\n",
      "    return x_pred, x_hist, y_hist\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 494
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sigma_calc(data, ampbins, variables=1):\n",
      "    C = 0.2\n",
      "    N = len(data)\n",
      "    sigmax = np.std(data)\n",
      "    # As given in Bauer\n",
      "    sigma = int(np.round(C * N**(-1/5) * sigmax * ampbins))\n",
      "    # With N power adjusted according to number of variables\n",
      "    #sigma = np.round(C * N**(-1/(4 + variables)) * sigmax * ampbins)\n",
      "    return sigma   \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 495
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def discretise(data, ampbins, maxsigma, variables=1):\n",
      "    \"\"\"Discretises the sample space.\n",
      "    Returns a disrete integer value for a sample from the sample space.\n",
      "    \n",
      "    data is the sample set that needs to be discretised, for example x_hist, x_pred or y_pred\n",
      "    \"\"\"\n",
      "    datamin = data.min()\n",
      "    datamax = data.max()\n",
      "    \n",
      "    sample_chi = np.zeros_like(data)\n",
      "    sigma = sigma_calc(data, ampbins, variables)\n",
      "    chiset = np.zeros([len(sample_chi), len(range(maxsigma * 2 + 1))])\n",
      "    ascale = np.zeros_like(data)\n",
      "    \n",
      "    for i in range(len(data)):\n",
      "        sample = data[i]\n",
      "        sample_chi[i] = int(np.round((ampbins - 1) * ((sample - datamin) / (datamax - datamin))) + 1)\n",
      "        chiset[i, :] = range(int(sample_chi[i] - maxsigma), int(sample_chi[i] + maxsigma + 1))\n",
      "    \n",
      "    return sample_chi, chiset, sigma"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 496
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def discrete_kernel_params(data, ampbins, variables=1):\n",
      "    \"\"\"Calculates the sigma and ascale parameters needed in Kernel esitmation.\n",
      "    Specific to each dataset for each individual variable if a multivariable PDF is to be estimated.\n",
      "\n",
      "    \"\"\"\n",
      "    sigma = sigma_calc(data, ampbins, variables=1)\n",
      "    ascale_sumterm = 0\n",
      "    ascale_chiset = range(-sigma, sigma)\n",
      "    for i in range(len(ascale_chiset)):\n",
      "        ascale_sumterm += np.exp(-((ascale_chiset[i]**2) / (sigma**2)))\n",
      "    ascale = ascale_sumterm * (1 / (sigma * np.pi))\n",
      "    return sigma, ascale\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 497
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def discrete_kernel_calc(ascale, sigma, dissample, disval):\n",
      "    \"\"\"Calculates a single single-variable Gaussian Kernel.\n",
      "\n",
      "    data is the single variable set of sample points\n",
      "    dissample (chi_i) is the discrete element of the data set used in the calculation of the single discrete kernel\n",
      "    disvalue (chi) is the discrete point according to which the probability density function is evaluated\n",
      "\n",
      "    \"\"\"\n",
      "    \n",
      "    #kernel = (1.0 / (np.sqrt(2*np.pi) * theta)) * np.exp(-(value - sample)**2 / (2 * (theta**2)))\n",
      "    kernel = (1.0 / (ascale * sigma * np.sqrt(np.pi))) * np.exp(-(disval - dissample)**2 / (sigma**2))\n",
      "    return kernel     "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 498
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def discrete_joint_pdf_eval(data, values, sigma, ascale, ampbins=1000):\n",
      "    \"\"\"Evaluates the joint (multivariable) probability density function for a specific set of values.\n",
      "\n",
      "    data is the multidimensional array containing all samples for all variables (chisets)\n",
      "    values is the set of values around which the joint PDF is to be evaluated (sample_chis)\n",
      "\n",
      "    \"\"\"\n",
      "    \n",
      "    numvars = np.shape(data)[0]\n",
      "    numsamples = len(data[0])\n",
      "    \n",
      "    # TODO: Test that samples and number of variable in data has the same dimension.\n",
      "    \n",
      "    kernel_sum = 0\n",
      "    #samples = np.zeros([numvars, ampbins])\n",
      "    #mins = np.zeros([1, numvars])\n",
      "    #maxs = np.zeros([1, numvars])\n",
      "    \n",
      "    \n",
      "    # Calculate the multivariable Kernel as the product of multiple univariate Kernels\n",
      "    # Calculate each univarite Kernel on its own    \n",
      "    \n",
      "    for i in range(numsamples):\n",
      "        kernel_prod = 1\n",
      "        for n in range(numvars):\n",
      "            kernel_prod = kernel_prod * discrete_kernel_calc(ascale[n], sigma[n], data[n][i], values[n])\n",
      "                \n",
      "        kernel_sum += kernel_prod\n",
      "    \n",
      "    prob = (1.0 / numsamples) * kernel_sum\n",
      "    return prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 499
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def discrete_pdfcalcs_custom(x_pred, x_hist, y_hist, x_pred_val, x_hist_val, y_hist_val, sigma, ascale):\n",
      "    \"\"\"Evaluates the PDFs required to calculate transfer entropy.\n",
      "    Follows the discrete method.\n",
      "\n",
      "    Currently only supports k = 1; l = 1\n",
      "\n",
      "    \"\"\"\n",
      "    # TODO: Generalize for k and l\n",
      "\n",
      "    # Get dimensions of vectors\n",
      "#    k = np.size(x_hist[:, 1])\n",
      "#    l = np.size(y_hist[:, 1])\n",
      "\n",
      "    # Calculate p(x_{i+h}, x_i, y_i)\n",
      "    # This data is already in discrete form - data_1 is stacked chi_sets\n",
      "    data_1 = [x_pred, x_hist[0], y_hist[0]]\n",
      "    pdf_1 = discrete_joint_pdf_eval(data_1, [x_pred_val, x_hist_val, y_hist_val], sigma, ascale) \n",
      "    #pdf_1 = stats.gaussian_kde(data_1, 'silverman')\n",
      "\n",
      "    # Calculate p(x_i, y_i)\n",
      "    data_2 = [x_hist[0], y_hist[0]]\n",
      "    pdf_2 = discrete_joint_pdf_eval(data_2, [x_hist_val, y_hist_val])\n",
      "    #pdf_2 = stats.gaussian_kde(data_2, 'silverman')\n",
      "\n",
      "    # Calculate p(x_{i+h}, x_i)\n",
      "    data_3 = [x_pred, x_hist[0]]\n",
      "    pdf_3 = discrete_joint_pdf_eval(data_3, [x_pred_val, x_hist_val])\n",
      "    #pdf_3 = stats.gaussian_kde(data_3, 'silverman')\n",
      "\n",
      "    # Calculate p(x_i)\n",
      "    data_4 = [x_hist[0]]\n",
      "    pdf_4 = discrete_joint_pdf_eval(data_4, [x_hist_val])\n",
      "    #pdf_4 = stats.gaussian_kde(data_4, 'silverman')\n",
      "\n",
      "    return pdf_1, pdf_2, pdf_3, pdf_4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 500
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def discrete_te_elementcalc_custom(x_pred, x_hist, y_hist, x_pred_val,\n",
      "                   x_hist_val, y_hist_val, sigma, ascale):\n",
      "    \"\"\"Calculate elements for summation for a specific set of coordinates\"\"\"\n",
      "\n",
      "    # Need to find a proper way to correct for cases when PDFs return 0\n",
      "    # Most of the PDF issues are associated with the x_hist values being\n",
      "    # very similar to the x_pred values\n",
      "    # Some very small negative values are sometimes returned\n",
      "    \n",
      "    [term1, term2, term3, term4] = discrete_pdfcalcs_custom(x_pred, x_hist, y_hist, x_pred_val, x_hist_val, y_hist_val, sigma, ascale)\n",
      "\n",
      "    logterm_num = (term1 / term2)\n",
      "    logterm_den = (term3 / term4)\n",
      "    coeff = term1\n",
      "    sum_element = coeff * np.log(logterm_num / logterm_den)\n",
      "    \n",
      "    # TODO: This still needs to be justified\n",
      "    if (sum_element == np.nan or sum_element < 0):\n",
      "        sum_element = 0\n",
      "\n",
      "    return sum_element"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 501
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def discrete_te_calc_custom(x_pred, x_hist, y_hist, ampbins=1000):\n",
      "    \"\"\"Calculates the transfer entropy between two variables from a set of\n",
      "    vectors already calculated.\n",
      "\n",
      "    ampbins is the number of amplitude bins to use over each variable\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    # First do an example for the case of k = l = 1\n",
      "    # TODO: Sum loops to allow for a general case\n",
      "    \n",
      "    # How many samples are used out of the whole dataset?\n",
      "    # For a start, use every sample from the set.\n",
      "    # Bauer2005 recommended that a minimum of 2000 samples is used.\n",
      "\n",
      "    # Calculate PDFs for all combinations required\n",
      "    # UPDATE: Not needed in custom method as PDFs are evaluated at each point\n",
      "    #[pdf_1, pdf_2, pdf_3, pdf_4] = pdfcalcs(x_pred, x_hist, y_hist)\n",
      "    \n",
      "    # Discretise data\n",
      "    \n",
      "    # Look for the largest sigma and use that to define the number of chivalues used for each variables\n",
      "    # as it appears that these need to be the same.\n",
      "    \n",
      "    data = [x_pred, x_hist, y_hist]\n",
      "    maxsigma = 0\n",
      "    for i in range(np.shape(data)[0]):\n",
      "        foo = sigma_calc(data[i], ampbins)\n",
      "        if foo > maxsigma:\n",
      "            maxsigma = foo\n",
      "   \n",
      "    print maxsigma\n",
      "    \n",
      "    [sample_chi_x_pred, chiset_x_pred, sigma_x_pred] = discretise(x_pred, ampbins, maxsigma)\n",
      "    [sample_chi_x_hist, chiset_x_hist, sigma_x_hist] = discretise(x_hist[0], ampbins, maxsigma)\n",
      "    [sample_chi_y_hist, chiset_y_hist, sigma_y_hist] = discretise(y_hist[0], ampbins, maxsigma)\n",
      "    \n",
      "    data = [x_pred, x_hist, y_hist]\n",
      "    numvars = np.shape(data)[0]\n",
      "    \n",
      "    sigma = np.zeros_like(range(numvars))\n",
      "    ascale = np.zeros_like(range(numvars))\n",
      "          \n",
      "    for m in range(numvars):\n",
      "        [sigma[m], ascale[m]] = discrete_kernel_params(data[m], ampbins, variables=1)\n",
      "\n",
      "    # Consecutive discrete sums\n",
      "    tesum = 0\n",
      "    counter = 0\n",
      "    for indx1 in range(len(sample_chi_x_pred)):\n",
      "        s1 = sample_chi_x_pred[indx1]\n",
      "        counter += 1.0\n",
      "        print ((counter / len(sample_chi_x_pred)) * 100), '%'\n",
      "        for indx2 in range(len(sample_chi_x_hist)):\n",
      "            s2 = sample_chi_x_hist[indx2]\n",
      "            for indx3 in range(len(sample_chi_y_hist)):\n",
      "                s3 = sample_chi_y_hist[indx3]\n",
      "                sum_element = discrete_te_elementcalc_custom(chiset_x_pred[indx1], chiset_x_hist[indx2], chiset_y_hist[indx3], s1, s2, s3, sigma, ascale)\n",
      "                tesum = tesum + sum_element\n",
      "    tentropy = tesum\n",
      "    return tentropy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 502
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def discrete_calculate_te_custom(delay, timelag, samples, sub_samples, ampbins, k=1, l=1):\n",
      "    \"\"\"Calculates the transfer entropy for a specific timelag (equal to\n",
      "    prediction horison) for a set of autoregressive data.\n",
      "\n",
      "    sub_samples is the amount of samples in the dataset used to calculate the\n",
      "    transfer entropy between two vectors (taken from the end of the dataset).\n",
      "    sub_samples <= samples\n",
      "\n",
      "    Currently only supports k = 1; l = 1;\n",
      "\n",
      "    You can search through a set of timelags in an attempt to identify the\n",
      "    original delay.\n",
      "    The transfer entropy should have a maximum value when timelag = delay\n",
      "    used to generate the autoregressive dataset.\n",
      "\n",
      "    \"\"\"\n",
      "    # Get autoregressive datasets\n",
      "    data = getdata(samples, delay)\n",
      "\n",
      "    [x_pred, x_hist, y_hist] = vectorselection(data, timelag,\n",
      "                                               sub_samples)\n",
      "\n",
      "    transentropy = discrete_te_calc_custom(x_pred, x_hist, y_hist, ampbins)\n",
      "\n",
      "    return transentropy\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 503
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test case"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 504
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DATA = getdata(3000, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 505
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[X_PRED, X_HIST, Y_HIST] = vectorselection(DATA, timelag=4,\n",
      "                                               sub_samples=2000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 506
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#TRANSENTROPY = discrete_te_calc_custom(X_PRED, X_HIST, Y_HIST, 1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 507
    }
   ],
   "metadata": {}
  }
 ]
}